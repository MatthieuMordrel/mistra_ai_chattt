/**
 * This file was auto-generated by openapi-typescript.
 * Do not make direct changes to the file.
 */

export interface paths {
  "/v1/models": {
    parameters: {
      query?: never;
      header?: never;
      path?: never;
      cookie?: never;
    };
    /**
     * List Models
     * @description List all models available to the user.
     */
    get: operations["list_models_v1_models_get"];
    put?: never;
    post?: never;
    delete?: never;
    options?: never;
    head?: never;
    patch?: never;
    trace?: never;
  };
  "/v1/models/{model_id}": {
    parameters: {
      query?: never;
      header?: never;
      path?: never;
      cookie?: never;
    };
    /**
     * Retrieve Model
     * @description Retrieve a model information.
     */
    get: operations["retrieve_model_v1_models__model_id__get"];
    put?: never;
    post?: never;
    /**
     * Delete Model
     * @description Delete a fine-tuned model.
     */
    delete: operations["delete_model_v1_models__model_id__delete"];
    options?: never;
    head?: never;
    patch?: never;
    trace?: never;
  };
  "/v1/files": {
    parameters: {
      query?: never;
      header?: never;
      path?: never;
      cookie?: never;
    };
    /**
     * List Files
     * @description Returns a list of files that belong to the user's organization.
     */
    get: operations["files_api_routes_list_files"];
    put?: never;
    /**
     * Upload File
     * @description Upload a file that can be used across various endpoints.
     *
     *     The size of individual files can be a maximum of 512 MB. The Fine-tuning API only supports .jsonl files.
     *
     *     Please contact us if you need to increase these storage limits.
     */
    post: operations["files_api_routes_upload_file"];
    delete?: never;
    options?: never;
    head?: never;
    patch?: never;
    trace?: never;
  };
  "/v1/files/{file_id}": {
    parameters: {
      query?: never;
      header?: never;
      path?: never;
      cookie?: never;
    };
    /**
     * Retrieve File
     * @description Returns information about a specific file.
     */
    get: operations["files_api_routes_retrieve_file"];
    put?: never;
    post?: never;
    /**
     * Delete File
     * @description Delete a file.
     */
    delete: operations["files_api_routes_delete_file"];
    options?: never;
    head?: never;
    patch?: never;
    trace?: never;
  };
  "/v1/files/{file_id}/content": {
    parameters: {
      query?: never;
      header?: never;
      path?: never;
      cookie?: never;
    };
    /**
     * Download File
     * @description Download a file
     */
    get: operations["files_api_routes_download_file"];
    put?: never;
    post?: never;
    delete?: never;
    options?: never;
    head?: never;
    patch?: never;
    trace?: never;
  };
  "/v1/files/{file_id}/url": {
    parameters: {
      query?: never;
      header?: never;
      path?: never;
      cookie?: never;
    };
    /** Get Signed Url */
    get: operations["files_api_routes_get_signed_url"];
    put?: never;
    post?: never;
    delete?: never;
    options?: never;
    head?: never;
    patch?: never;
    trace?: never;
  };
  "/v1/fine_tuning/jobs": {
    parameters: {
      query?: never;
      header?: never;
      path?: never;
      cookie?: never;
    };
    /**
     * Get Fine Tuning Jobs
     * @description Get a list of fine-tuning jobs for your organization and user.
     */
    get: operations["jobs_api_routes_fine_tuning_get_fine_tuning_jobs"];
    put?: never;
    /**
     * Create Fine Tuning Job
     * @description Create a new fine-tuning job, it will be queued for processing.
     */
    post: operations["jobs_api_routes_fine_tuning_create_fine_tuning_job"];
    delete?: never;
    options?: never;
    head?: never;
    patch?: never;
    trace?: never;
  };
  "/v1/fine_tuning/jobs/{job_id}": {
    parameters: {
      query?: never;
      header?: never;
      path?: never;
      cookie?: never;
    };
    /**
     * Get Fine Tuning Job
     * @description Get a fine-tuned job details by its UUID.
     */
    get: operations["jobs_api_routes_fine_tuning_get_fine_tuning_job"];
    put?: never;
    post?: never;
    delete?: never;
    options?: never;
    head?: never;
    patch?: never;
    trace?: never;
  };
  "/v1/fine_tuning/jobs/{job_id}/cancel": {
    parameters: {
      query?: never;
      header?: never;
      path?: never;
      cookie?: never;
    };
    get?: never;
    put?: never;
    /**
     * Cancel Fine Tuning Job
     * @description Request the cancellation of a fine tuning job.
     */
    post: operations["jobs_api_routes_fine_tuning_cancel_fine_tuning_job"];
    delete?: never;
    options?: never;
    head?: never;
    patch?: never;
    trace?: never;
  };
  "/v1/fine_tuning/jobs/{job_id}/start": {
    parameters: {
      query?: never;
      header?: never;
      path?: never;
      cookie?: never;
    };
    get?: never;
    put?: never;
    /**
     * Start Fine Tuning Job
     * @description Request the start of a validated fine tuning job.
     */
    post: operations["jobs_api_routes_fine_tuning_start_fine_tuning_job"];
    delete?: never;
    options?: never;
    head?: never;
    patch?: never;
    trace?: never;
  };
  "/v1/fine_tuning/models/{model_id}": {
    parameters: {
      query?: never;
      header?: never;
      path?: never;
      cookie?: never;
    };
    get?: never;
    put?: never;
    post?: never;
    delete?: never;
    options?: never;
    head?: never;
    /**
     * Update Fine Tuned Model
     * @description Update a model name or description.
     */
    patch: operations["jobs_api_routes_fine_tuning_update_fine_tuned_model"];
    trace?: never;
  };
  "/v1/fine_tuning/models/{model_id}/archive": {
    parameters: {
      query?: never;
      header?: never;
      path?: never;
      cookie?: never;
    };
    get?: never;
    put?: never;
    /**
     * Archive Fine Tuned Model
     * @description Archive a fine-tuned model.
     */
    post: operations["jobs_api_routes_fine_tuning_archive_fine_tuned_model"];
    /**
     * Unarchive Fine Tuned Model
     * @description Un-archive a fine-tuned model.
     */
    delete: operations["jobs_api_routes_fine_tuning_unarchive_fine_tuned_model"];
    options?: never;
    head?: never;
    patch?: never;
    trace?: never;
  };
  "/v1/batch/jobs": {
    parameters: {
      query?: never;
      header?: never;
      path?: never;
      cookie?: never;
    };
    /**
     * Get Batch Jobs
     * @description Get a list of batch jobs for your organization and user.
     */
    get: operations["jobs_api_routes_batch_get_batch_jobs"];
    put?: never;
    /**
     * Create Batch Job
     * @description Create a new batch job, it will be queued for processing.
     */
    post: operations["jobs_api_routes_batch_create_batch_job"];
    delete?: never;
    options?: never;
    head?: never;
    patch?: never;
    trace?: never;
  };
  "/v1/batch/jobs/{job_id}": {
    parameters: {
      query?: never;
      header?: never;
      path?: never;
      cookie?: never;
    };
    /**
     * Get Batch Job
     * @description Get a batch job details by its UUID.
     */
    get: operations["jobs_api_routes_batch_get_batch_job"];
    put?: never;
    post?: never;
    delete?: never;
    options?: never;
    head?: never;
    patch?: never;
    trace?: never;
  };
  "/v1/batch/jobs/{job_id}/cancel": {
    parameters: {
      query?: never;
      header?: never;
      path?: never;
      cookie?: never;
    };
    get?: never;
    put?: never;
    /**
     * Cancel Batch Job
     * @description Request the cancellation of a batch job.
     */
    post: operations["jobs_api_routes_batch_cancel_batch_job"];
    delete?: never;
    options?: never;
    head?: never;
    patch?: never;
    trace?: never;
  };
  "/v1/chat/completions": {
    parameters: {
      query?: never;
      header?: never;
      path?: never;
      cookie?: never;
    };
    get?: never;
    put?: never;
    /** Chat Completion */
    post: operations["chat_completion_v1_chat_completions_post"];
    delete?: never;
    options?: never;
    head?: never;
    patch?: never;
    trace?: never;
  };
  "/v1/fim/completions": {
    parameters: {
      query?: never;
      header?: never;
      path?: never;
      cookie?: never;
    };
    get?: never;
    put?: never;
    /**
     * Fim Completion
     * @description FIM completion.
     */
    post: operations["fim_completion_v1_fim_completions_post"];
    delete?: never;
    options?: never;
    head?: never;
    patch?: never;
    trace?: never;
  };
  "/v1/ocr": {
    parameters: {
      query?: never;
      header?: never;
      path?: never;
      cookie?: never;
    };
    get?: never;
    put?: never;
    /** OCR */
    post: operations["ocr_v1_ocr_post"];
    delete?: never;
    options?: never;
    head?: never;
    patch?: never;
    trace?: never;
  };
  "/v1/moderations": {
    parameters: {
      query?: never;
      header?: never;
      path?: never;
      cookie?: never;
    };
    get?: never;
    put?: never;
    /** Moderations */
    post: operations["moderations_v1_moderations_post"];
    delete?: never;
    options?: never;
    head?: never;
    patch?: never;
    trace?: never;
  };
  "/v1/chat/moderations": {
    parameters: {
      query?: never;
      header?: never;
      path?: never;
      cookie?: never;
    };
    get?: never;
    put?: never;
    /** Moderations Chat */
    post: operations["moderations_chat_v1_chat_moderations_post"];
    delete?: never;
    options?: never;
    head?: never;
    patch?: never;
    trace?: never;
  };
  "/v1/embeddings": {
    parameters: {
      query?: never;
      header?: never;
      path?: never;
      cookie?: never;
    };
    get?: never;
    put?: never;
    /**
     * Embeddings
     * @description Embeddings
     */
    post: operations["embeddings_v1_embeddings_post"];
    delete?: never;
    options?: never;
    head?: never;
    patch?: never;
    trace?: never;
  };
  "/v1/agents/completions": {
    parameters: {
      query?: never;
      header?: never;
      path?: never;
      cookie?: never;
    };
    get?: never;
    put?: never;
    /** Agents Completion */
    post: operations["agents_completion_v1_agents_completions_post"];
    delete?: never;
    options?: never;
    head?: never;
    patch?: never;
    trace?: never;
  };
}
export type webhooks = Record<string, never>;
export interface components {
  schemas: {
    /** BaseModelCard */
    BaseModelCard: {
      /** Id */
      id: string;
      /**
       * Object
       * @default model
       */
      object: string;
      /** Created */
      created?: number;
      /**
       * Owned By
       * @default mistralai
       */
      owned_by: string;
      capabilities: components["schemas"]["ModelCapabilities"];
      /** Name */
      name?: string | null;
      /** Description */
      description?: string | null;
      /**
       * Max Context Length
       * @default 32768
       */
      max_context_length: number;
      /**
       * Aliases
       * @default []
       */
      aliases: string[];
      /** Deprecation */
      deprecation?: string | null;
      /** Default Model Temperature */
      default_model_temperature?: number | null;
      /**
       * @description discriminator enum property added by openapi-typescript
       * @enum {string}
       */
      type: "base";
    };
    /** DeleteModelOut */
    DeleteModelOut: {
      /**
       * Id
       * @description The ID of the deleted model.
       */
      id: string;
      /**
       * Object
       * @description The object type that was deleted
       * @default model
       */
      object: string;
      /**
       * Deleted
       * @description The deletion status
       * @default true
       */
      deleted: boolean;
    };
    /**
     * FTModelCard
     * @description Extra fields for fine-tuned models.
     */
    FTModelCard: {
      /** Id */
      id: string;
      /**
       * Object
       * @default model
       */
      object: string;
      /** Created */
      created?: number;
      /**
       * Owned By
       * @default mistralai
       */
      owned_by: string;
      capabilities: components["schemas"]["ModelCapabilities"];
      /** Name */
      name?: string | null;
      /** Description */
      description?: string | null;
      /**
       * Max Context Length
       * @default 32768
       */
      max_context_length: number;
      /**
       * Aliases
       * @default []
       */
      aliases: string[];
      /** Deprecation */
      deprecation?: string | null;
      /** Default Model Temperature */
      default_model_temperature?: number | null;
      /**
       * @description discriminator enum property added by openapi-typescript
       * @enum {string}
       */
      type: "fine-tuned";
      /** Job */
      job: string;
      /** Root */
      root: string;
      /**
       * Archived
       * @default false
       */
      archived: boolean;
    };
    /** HTTPValidationError */
    HTTPValidationError: {
      /** Detail */
      detail?: components["schemas"]["ValidationError"][];
    };
    /** ModelCapabilities */
    ModelCapabilities: {
      /**
       * Completion Chat
       * @default true
       */
      completion_chat: boolean;
      /**
       * Completion Fim
       * @default false
       */
      completion_fim: boolean;
      /**
       * Function Calling
       * @default true
       */
      function_calling: boolean;
      /**
       * Fine Tuning
       * @default false
       */
      fine_tuning: boolean;
      /**
       * Vision
       * @default false
       */
      vision: boolean;
    };
    /** ModelList */
    ModelList: {
      /**
       * Object
       * @default list
       */
      object: string;
      /** Data */
      data?: (
        | components["schemas"]["BaseModelCard"]
        | components["schemas"]["FTModelCard"]
      )[];
    };
    /** ValidationError */
    ValidationError: {
      /** Location */
      loc: (string | number)[];
      /** Message */
      msg: string;
      /** Error Type */
      type: string;
    };
    /**
     * FilePurpose
     * @enum {string}
     */
    FilePurpose: "fine-tune" | "batch";
    /**
     * SampleType
     * @enum {string}
     */
    SampleType:
      | "pretrain"
      | "instruct"
      | "batch_request"
      | "batch_result"
      | "batch_error";
    /**
     * Source
     * @enum {string}
     */
    Source: "upload" | "repository" | "mistral";
    /** UploadFileOut */
    UploadFileOut: {
      /**
       * Id
       * Format: uuid
       * @description The unique identifier of the file.
       */
      id: string;
      /**
       * Object
       * @description The object type, which is always "file".
       */
      object: string;
      /**
       * Bytes
       * @description The size of the file, in bytes.
       */
      bytes: number;
      /**
       * Created At
       * @description The UNIX timestamp (in seconds) of the event.
       */
      created_at: number;
      /**
       * Filename
       * @description The name of the uploaded file.
       */
      filename: string;
      /** @description The intended purpose of the uploaded file. Only accepts fine-tuning (`fine-tune`) for now. */
      purpose: components["schemas"]["FilePurpose"];
      sample_type: components["schemas"]["SampleType"];
      /** Num Lines */
      num_lines?: number | null;
      source: components["schemas"]["Source"];
    };
    /** FileSchema */
    FileSchema: {
      /**
       * Id
       * Format: uuid
       * @description The unique identifier of the file.
       */
      id: string;
      /**
       * Object
       * @description The object type, which is always "file".
       */
      object: string;
      /**
       * Bytes
       * @description The size of the file, in bytes.
       */
      bytes: number;
      /**
       * Created At
       * @description The UNIX timestamp (in seconds) of the event.
       */
      created_at: number;
      /**
       * Filename
       * @description The name of the uploaded file.
       */
      filename: string;
      /** @description The intended purpose of the uploaded file. Only accepts fine-tuning (`fine-tune`) for now. */
      purpose: components["schemas"]["FilePurpose"];
      sample_type: components["schemas"]["SampleType"];
      /** Num Lines */
      num_lines?: number | null;
      source: components["schemas"]["Source"];
    };
    /** ListFilesOut */
    ListFilesOut: {
      /** Data */
      data: components["schemas"]["FileSchema"][];
      /** Object */
      object: string;
      /** Total */
      total: number;
    };
    /** RetrieveFileOut */
    RetrieveFileOut: {
      /**
       * Id
       * Format: uuid
       * @description The unique identifier of the file.
       */
      id: string;
      /**
       * Object
       * @description The object type, which is always "file".
       */
      object: string;
      /**
       * Bytes
       * @description The size of the file, in bytes.
       */
      bytes: number;
      /**
       * Created At
       * @description The UNIX timestamp (in seconds) of the event.
       */
      created_at: number;
      /**
       * Filename
       * @description The name of the uploaded file.
       */
      filename: string;
      /** @description The intended purpose of the uploaded file. Only accepts fine-tuning (`fine-tune`) for now. */
      purpose: components["schemas"]["FilePurpose"];
      sample_type: components["schemas"]["SampleType"];
      /** Num Lines */
      num_lines?: number | null;
      source: components["schemas"]["Source"];
      /** Deleted */
      deleted: boolean;
    };
    /** DeleteFileOut */
    DeleteFileOut: {
      /**
       * Id
       * Format: uuid
       * @description The ID of the deleted file.
       */
      id: string;
      /**
       * Object
       * @description The object type that was deleted
       */
      object: string;
      /**
       * Deleted
       * @description The deletion status.
       */
      deleted: boolean;
    };
    /** FileSignedURL */
    FileSignedURL: {
      /** Url */
      url: string;
    };
    /**
     * FineTuneableModel
     * @description The name of the model to fine-tune.
     * @enum {string}
     */
    FineTuneableModel:
      | "open-mistral-7b"
      | "mistral-small-latest"
      | "codestral-latest"
      | "mistral-large-latest"
      | "open-mistral-nemo"
      | "ministral-3b-latest";
    /** GithubRepositoryOut */
    GithubRepositoryOut: {
      /**
       * @description discriminator enum property added by openapi-typescript
       * @enum {string}
       */
      type: "github";
      /** Name */
      name: string;
      /** Owner */
      owner: string;
      /** Ref */
      ref?: string | null;
      /**
       * Weight
       * @default 1
       */
      weight: number;
      /** Commit Id */
      commit_id: string;
    };
    /** JobMetadataOut */
    JobMetadataOut: {
      /** Expected Duration Seconds */
      expected_duration_seconds?: number | null;
      /** Cost */
      cost?: number | null;
      /** Cost Currency */
      cost_currency?: string | null;
      /** Train Tokens Per Step */
      train_tokens_per_step?: number | null;
      /** Train Tokens */
      train_tokens?: number | null;
      /** Data Tokens */
      data_tokens?: number | null;
      /** Estimated Start Time */
      estimated_start_time?: number | null;
    };
    /** JobOut */
    JobOut: {
      /**
       * Id
       * Format: uuid
       * @description The ID of the job.
       */
      id: string;
      /** Auto Start */
      auto_start: boolean;
      hyperparameters: components["schemas"]["TrainingParameters"];
      model: components["schemas"]["FineTuneableModel"];
      /**
       * Status
       * @description The current status of the fine-tuning job.
       * @enum {string}
       */
      status:
        | "QUEUED"
        | "STARTED"
        | "VALIDATING"
        | "VALIDATED"
        | "RUNNING"
        | "FAILED_VALIDATION"
        | "FAILED"
        | "SUCCESS"
        | "CANCELLED"
        | "CANCELLATION_REQUESTED";
      /**
       * Job Type
       * @description The type of job (`FT` for fine-tuning).
       */
      job_type: string;
      /**
       * Created At
       * @description The UNIX timestamp (in seconds) for when the fine-tuning job was created.
       */
      created_at: number;
      /**
       * Modified At
       * @description The UNIX timestamp (in seconds) for when the fine-tuning job was last modified.
       */
      modified_at: number;
      /**
       * Training Files
       * @description A list containing the IDs of uploaded files that contain training data.
       */
      training_files: string[];
      /**
       * Validation Files
       * @description A list containing the IDs of uploaded files that contain validation data.
       * @default []
       */
      validation_files: string[] | null;
      /**
       * Object
       * @description The object type of the fine-tuning job.
       * @default job
       * @constant
       * @enum {string}
       */
      object: "job";
      /**
       * Fine Tuned Model
       * @description The name of the fine-tuned model that is being created. The value will be `null` if the fine-tuning job is still running.
       */
      fine_tuned_model?: string | null;
      /**
       * Suffix
       * @description Optional text/code that adds more context for the model. When given a `prompt` and a `suffix` the model will fill what is between them. When `suffix` is not provided, the model will simply execute completion starting with `prompt`.
       */
      suffix?: string | null;
      /**
       * Integrations
       * @description A list of integrations enabled for your fine-tuning job.
       */
      integrations?: components["schemas"]["WandbIntegrationOut"][] | null;
      /**
       * Trained Tokens
       * @description Total number of tokens trained.
       */
      trained_tokens?: number | null;
      /**
       * Repositories
       * @default []
       */
      repositories: components["schemas"]["GithubRepositoryOut"][];
      metadata?: components["schemas"]["JobMetadataOut"] | null;
    };
    /** JobsOut */
    JobsOut: {
      /**
       * Data
       * @default []
       */
      data: components["schemas"]["JobOut"][];
      /**
       * Object
       * @default list
       * @constant
       * @enum {string}
       */
      object: "list";
      /** Total */
      total: number;
    };
    /** TrainingParameters */
    TrainingParameters: {
      /** Training Steps */
      training_steps?: number | null;
      /**
       * Learning Rate
       * @default 0.0001
       */
      learning_rate: number;
      /**
       * Weight Decay
       * @default 0.1
       */
      weight_decay: number | null;
      /**
       * Warmup Fraction
       * @default 0.05
       */
      warmup_fraction: number | null;
      /** Epochs */
      epochs?: number | null;
      /**
       * Fim Ratio
       * @default 0.9
       */
      fim_ratio: number | null;
      /** Seq Len */
      seq_len?: number | null;
    };
    /** WandbIntegrationOut */
    WandbIntegrationOut: {
      /**
       * @description discriminator enum property added by openapi-typescript
       * @enum {string}
       */
      type: "wandb";
      /**
       * Project
       * @description The name of the project that the new run will be created under.
       */
      project: string;
      /**
       * Name
       * @description A display name to set for the run. If not set, will use the job ID as the name.
       */
      name?: string | null;
      /** Run Name */
      run_name?: string | null;
    };
    /** LegacyJobMetadataOut */
    LegacyJobMetadataOut: {
      /**
       * Expected Duration Seconds
       * @description The approximated time (in seconds) for the fine-tuning process to complete.
       */
      expected_duration_seconds?: number | null;
      /**
       * Cost
       * @description The cost of the fine-tuning job.
       */
      cost?: number | null;
      /**
       * Cost Currency
       * @description The currency used for the fine-tuning job cost.
       */
      cost_currency?: string | null;
      /**
       * Train Tokens Per Step
       * @description The number of tokens consumed by one training step.
       */
      train_tokens_per_step?: number | null;
      /**
       * Train Tokens
       * @description The total number of tokens used during the fine-tuning process.
       */
      train_tokens?: number | null;
      /**
       * Data Tokens
       * @description The total number of tokens in the training dataset.
       */
      data_tokens?: number | null;
      /** Estimated Start Time */
      estimated_start_time?: number | null;
      /**
       * Deprecated
       * @default true
       */
      deprecated: boolean;
      /** Details */
      details: string;
      /**
       * Epochs
       * @description The number of complete passes through the entire training dataset.
       */
      epochs?: number | null;
      /**
       * Training Steps
       * @description The number of training steps to perform. A training step refers to a single update of the model weights during the fine-tuning process. This update is typically calculated using a batch of samples from the training dataset.
       */
      training_steps?: number | null;
      /**
       * Object
       * @default job.metadata
       * @constant
       * @enum {string}
       */
      object: "job.metadata";
    };
    /** GithubRepositoryIn */
    GithubRepositoryIn: {
      /**
       * @description discriminator enum property added by openapi-typescript
       * @enum {string}
       */
      type: "github";
      /** Name */
      name: string;
      /** Owner */
      owner: string;
      /** Ref */
      ref?: string | null;
      /**
       * Weight
       * @default 1
       */
      weight: number;
      /** Token */
      token: string;
    };
    /** JobIn */
    JobIn: {
      model: components["schemas"]["FineTuneableModel"];
      /**
       * Training Files
       * @default []
       */
      training_files: components["schemas"]["TrainingFile"][];
      /**
       * Validation Files
       * @description A list containing the IDs of uploaded files that contain validation data. If you provide these files, the data is used to generate validation metrics periodically during fine-tuning. These metrics can be viewed in `checkpoints` when getting the status of a running fine-tuning job. The same data should not be present in both train and validation files.
       */
      validation_files?: string[] | null;
      hyperparameters: components["schemas"]["TrainingParametersIn"];
      /**
       * Suffix
       * @description A string that will be added to your fine-tuning model name. For example, a suffix of "my-great-model" would produce a model name like `ft:open-mistral-7b:my-great-model:xxx...`
       */
      suffix?: string | null;
      /**
       * Integrations
       * @description A list of integrations to enable for your fine-tuning job.
       */
      integrations?: components["schemas"]["WandbIntegration"][] | null;
      /**
       * Repositories
       * @default []
       */
      repositories: components["schemas"]["GithubRepositoryIn"][];
      /**
       * Auto Start
       * @description This field will be required in a future release.
       */
      auto_start?: boolean;
    };
    /** TrainingFile */
    TrainingFile: {
      /**
       * File Id
       * Format: uuid
       */
      file_id: string;
      /**
       * Weight
       * @default 1
       */
      weight: number;
    };
    /**
     * TrainingParametersIn
     * @description The fine-tuning hyperparameter settings used in a fine-tune job.
     */
    TrainingParametersIn: {
      /**
       * Training Steps
       * @description The number of training steps to perform. A training step refers to a single update of the model weights during the fine-tuning process. This update is typically calculated using a batch of samples from the training dataset.
       */
      training_steps?: number | null;
      /**
       * Learning Rate
       * @description A parameter describing how much to adjust the pre-trained model's weights in response to the estimated error each time the weights are updated during the fine-tuning process.
       * @default 0.0001
       */
      learning_rate: number;
      /**
       * Weight Decay
       * @description (Advanced Usage) Weight decay adds a term to the loss function that is proportional to the sum of the squared weights. This term reduces the magnitude of the weights and prevents them from growing too large.
       * @default 0.1
       */
      weight_decay: number | null;
      /**
       * Warmup Fraction
       * @description (Advanced Usage) A parameter that specifies the percentage of the total training steps at which the learning rate warm-up phase ends. During this phase, the learning rate gradually increases from a small value to the initial learning rate, helping to stabilize the training process and improve convergence. Similar to `pct_start` in [mistral-finetune](https://github.com/mistralai/mistral-finetune)
       * @default 0.05
       */
      warmup_fraction: number | null;
      /** Epochs */
      epochs?: number | null;
      /**
       * Fim Ratio
       * @default 0.9
       */
      fim_ratio: number | null;
      /** Seq Len */
      seq_len?: number | null;
    };
    /** WandbIntegration */
    WandbIntegration: {
      /**
       * @description discriminator enum property added by openapi-typescript
       * @enum {string}
       */
      type: "wandb";
      /**
       * Project
       * @description The name of the project that the new run will be created under.
       */
      project: string;
      /**
       * Name
       * @description A display name to set for the run. If not set, will use the job ID as the name.
       */
      name?: string | null;
      /**
       * Api Key
       * @description The WandB API key to use for authentication.
       */
      api_key: string;
      /** Run Name */
      run_name?: string | null;
    };
    /** CheckpointOut */
    CheckpointOut: {
      metrics: components["schemas"]["MetricOut"];
      /**
       * Step Number
       * @description The step number that the checkpoint was created at.
       */
      step_number: number;
      /**
       * Created At
       * @description The UNIX timestamp (in seconds) for when the checkpoint was created.
       */
      created_at: number;
    };
    /** DetailedJobOut */
    DetailedJobOut: {
      /**
       * Id
       * Format: uuid
       */
      id: string;
      /** Auto Start */
      auto_start: boolean;
      hyperparameters: components["schemas"]["TrainingParameters"];
      model: components["schemas"]["FineTuneableModel"];
      /**
       * Status
       * @enum {string}
       */
      status:
        | "QUEUED"
        | "STARTED"
        | "VALIDATING"
        | "VALIDATED"
        | "RUNNING"
        | "FAILED_VALIDATION"
        | "FAILED"
        | "SUCCESS"
        | "CANCELLED"
        | "CANCELLATION_REQUESTED";
      /** Job Type */
      job_type: string;
      /** Created At */
      created_at: number;
      /** Modified At */
      modified_at: number;
      /** Training Files */
      training_files: string[];
      /**
       * Validation Files
       * @default []
       */
      validation_files: string[] | null;
      /**
       * Object
       * @default job
       * @constant
       * @enum {string}
       */
      object: "job";
      /** Fine Tuned Model */
      fine_tuned_model?: string | null;
      /** Suffix */
      suffix?: string | null;
      /** Integrations */
      integrations?: components["schemas"]["WandbIntegrationOut"][] | null;
      /** Trained Tokens */
      trained_tokens?: number | null;
      /**
       * Repositories
       * @default []
       */
      repositories: components["schemas"]["GithubRepositoryOut"][];
      metadata?: components["schemas"]["JobMetadataOut"] | null;
      /**
       * Events
       * @description Event items are created every time the status of a fine-tuning job changes. The timestamped list of all events is accessible here.
       * @default []
       */
      events: components["schemas"]["EventOut"][];
      /**
       * Checkpoints
       * @default []
       */
      checkpoints: components["schemas"]["CheckpointOut"][];
    };
    /** EventOut */
    EventOut: {
      /**
       * Name
       * @description The name of the event.
       */
      name: string;
      /** Data */
      data?: {
        [key: string]: unknown;
      } | null;
      /**
       * Created At
       * @description The UNIX timestamp (in seconds) of the event.
       */
      created_at: number;
    };
    /**
     * MetricOut
     * @description Metrics at the step number during the fine-tuning job. Use these metrics to assess if the training is going smoothly (loss should decrease, token accuracy should increase).
     */
    MetricOut: {
      /** Train Loss */
      train_loss?: number | null;
      /** Valid Loss */
      valid_loss?: number | null;
      /** Valid Mean Token Accuracy */
      valid_mean_token_accuracy?: number | null;
    };
    /** FTModelCapabilitiesOut */
    FTModelCapabilitiesOut: {
      /**
       * Completion Chat
       * @default true
       */
      completion_chat: boolean;
      /**
       * Completion Fim
       * @default false
       */
      completion_fim: boolean;
      /**
       * Function Calling
       * @default false
       */
      function_calling: boolean;
      /**
       * Fine Tuning
       * @default false
       */
      fine_tuning: boolean;
    };
    /** FTModelOut */
    FTModelOut: {
      /** Id */
      id: string;
      /**
       * Object
       * @default model
       * @constant
       * @enum {string}
       */
      object: "model";
      /** Created */
      created: number;
      /** Owned By */
      owned_by: string;
      /** Root */
      root: string;
      /** Archived */
      archived: boolean;
      /** Name */
      name?: string | null;
      /** Description */
      description?: string | null;
      capabilities: components["schemas"]["FTModelCapabilitiesOut"];
      /**
       * Max Context Length
       * @default 32768
       */
      max_context_length: number;
      /**
       * Aliases
       * @default []
       */
      aliases: string[];
      /**
       * Job
       * Format: uuid
       */
      job: string;
    };
    /** UpdateFTModelIn */
    UpdateFTModelIn: {
      /** Name */
      name?: string | null;
      /** Description */
      description?: string | null;
    };
    /** ArchiveFTModelOut */
    ArchiveFTModelOut: {
      /** Id */
      id: string;
      /**
       * Object
       * @default model
       * @constant
       * @enum {string}
       */
      object: "model";
      /**
       * Archived
       * @default true
       */
      archived: boolean;
    };
    /** UnarchiveFTModelOut */
    UnarchiveFTModelOut: {
      /** Id */
      id: string;
      /**
       * Object
       * @default model
       * @constant
       * @enum {string}
       */
      object: "model";
      /**
       * Archived
       * @default false
       */
      archived: boolean;
    };
    /**
     * BatchJobStatus
     * @enum {string}
     */
    BatchJobStatus:
      | "QUEUED"
      | "RUNNING"
      | "SUCCESS"
      | "FAILED"
      | "TIMEOUT_EXCEEDED"
      | "CANCELLATION_REQUESTED"
      | "CANCELLED";
    /** BatchError */
    BatchError: {
      /** Message */
      message: string;
      /**
       * Count
       * @default 1
       */
      count: number;
    };
    /** BatchJobOut */
    BatchJobOut: {
      /** Id */
      id: string;
      /**
       * Object
       * @default batch
       * @constant
       * @enum {string}
       */
      object: "batch";
      /** Input Files */
      input_files: string[];
      /** Metadata */
      metadata?: {
        [key: string]: unknown;
      } | null;
      /** Endpoint */
      endpoint: string;
      /** Model */
      model: string;
      /** Output File */
      output_file?: string | null;
      /** Error File */
      error_file?: string | null;
      /** Errors */
      errors: components["schemas"]["BatchError"][];
      status: components["schemas"]["BatchJobStatus"];
      /** Created At */
      created_at: number;
      /** Total Requests */
      total_requests: number;
      /** Completed Requests */
      completed_requests: number;
      /** Succeeded Requests */
      succeeded_requests: number;
      /** Failed Requests */
      failed_requests: number;
      /** Started At */
      started_at?: number | null;
      /** Completed At */
      completed_at?: number | null;
    };
    /** BatchJobsOut */
    BatchJobsOut: {
      /**
       * Data
       * @default []
       */
      data: components["schemas"]["BatchJobOut"][];
      /**
       * Object
       * @default list
       * @constant
       * @enum {string}
       */
      object: "list";
      /** Total */
      total: number;
    };
    /**
     * ApiEndpoint
     * @enum {string}
     */
    ApiEndpoint:
      | "/v1/chat/completions"
      | "/v1/embeddings"
      | "/v1/fim/completions"
      | "/v1/moderations"
      | "/v1/chat/moderations";
    /** BatchJobIn */
    BatchJobIn: {
      /** Input Files */
      input_files: string[];
      endpoint: components["schemas"]["ApiEndpoint"];
      /** Model */
      model: string;
      /** Metadata */
      metadata?: {
        [key: string]: string;
      } | null;
      /**
       * Timeout Hours
       * @default 24
       */
      timeout_hours: number;
    };
    /** AssistantMessage */
    AssistantMessage: {
      /** Content */
      content?: string | null | components["schemas"]["ContentChunk"][];
      /** Tool Calls */
      tool_calls?: components["schemas"]["ToolCall"][] | null;
      /**
       * Prefix
       * @description Set this to `true` when adding an assistant message as prefix to condition the model response. The role of the prefix message is to force the model to start its answer by the content of the message.
       * @default false
       */
      prefix: boolean;
      /**
       * @description discriminator enum property added by openapi-typescript
       * @enum {string}
       */
      role: "assistant";
    };
    /** ChatCompletionRequest */
    ChatCompletionRequest: {
      /**
       * Model
       * @description ID of the model to use. You can use the [List Available Models](/api/#tag/models/operation/list_models_v1_models_get) API to see all of your available models, or see our [Model overview](/models) for model descriptions.
       */
      model: string;
      /**
       * Temperature
       * @description What sampling temperature to use, we recommend between 0.0 and 0.7. Higher values like 0.7 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. We generally recommend altering this or `top_p` but not both. The default value varies depending on the model you are targeting. Call the `/models` endpoint to retrieve the appropriate value.
       */
      temperature?: number | null;
      /**
       * Top P
       * @description Nucleus sampling, where the model considers the results of the tokens with `top_p` probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered. We generally recommend altering this or `temperature` but not both.
       * @default 1
       */
      top_p: number;
      /**
       * Max Tokens
       * @description The maximum number of tokens to generate in the completion. The token count of your prompt plus `max_tokens` cannot exceed the model's context length.
       */
      max_tokens?: number | null;
      /**
       * Stream
       * @description Whether to stream back partial progress. If set, tokens will be sent as data-only server-side events as they become available, with the stream terminated by a data: [DONE] message. Otherwise, the server will hold the request open until the timeout or until completion, with the response containing the full result as JSON.
       * @default false
       */
      stream: boolean;
      /**
       * Stop
       * @description Stop generation if this token is detected. Or if one of these tokens is detected when providing an array
       */
      stop?: string | string[];
      /**
       * Random Seed
       * @description The seed to use for random sampling. If set, different calls will generate deterministic results.
       */
      random_seed?: number | null;
      /**
       * Messages
       * @description The prompt(s) to generate completions for, encoded as a list of dict with role and content.
       */
      messages: (
        | components["schemas"]["SystemMessage"]
        | components["schemas"]["UserMessage"]
        | components["schemas"]["AssistantMessage"]
        | components["schemas"]["ToolMessage"]
      )[];
      response_format?: components["schemas"]["ResponseFormat"];
      /** Tools */
      tools?: components["schemas"]["Tool"][] | null;
      /**
       * Tool Choice
       * @default auto
       */
      tool_choice:
        | components["schemas"]["ToolChoice"]
        | components["schemas"]["ToolChoiceEnum"];
      /**
       * Presence Penalty
       * @description presence_penalty determines how much the model penalizes the repetition of words or phrases. A higher presence penalty encourages the model to use a wider variety of words and phrases, making the output more diverse and creative.
       * @default 0
       */
      presence_penalty: number;
      /**
       * Frequency Penalty
       * @description frequency_penalty penalizes the repetition of words based on their frequency in the generated text. A higher frequency penalty discourages the model from repeating words that have already appeared frequently in the output, promoting diversity and reducing repetition.
       * @default 0
       */
      frequency_penalty: number;
      /**
       * N
       * @description Number of completions to return for each request, input tokens are only billed once.
       */
      n?: number | null;
      /**
       * @description Enable users to specify expected results, optimizing response times by leveraging known or predictable content. This approach is especially effective for updating text documents or code files with minimal changes, reducing latency while maintaining high-quality results.
       * @default {
       *       "type": "content",
       *       "content": ""
       *     }
       */
      prediction: components["schemas"]["Prediction"];
      /**
       * @description Whether to inject a safety prompt before all conversations.
       * @default false
       */
      safe_prompt: boolean;
    };
    /** ChatModerationRequest */
    ChatModerationRequest: {
      /** Model */
      model: string;
      /**
       * Input
       * @description Chat to classify
       */
      input:
        | (
            | components["schemas"]["SystemMessage"]
            | components["schemas"]["UserMessage"]
            | components["schemas"]["AssistantMessage"]
            | components["schemas"]["ToolMessage"]
          )[]
        | (
            | components["schemas"]["SystemMessage"]
            | components["schemas"]["UserMessage"]
            | components["schemas"]["AssistantMessage"]
            | components["schemas"]["ToolMessage"]
          )[][];
      /**
       * Truncate For Context Length
       * @default false
       */
      truncate_for_context_length: boolean;
    };
    /** ClassificationRequest */
    ClassificationRequest: {
      /**
       * Model
       * @description ID of the model to use.
       */
      model: string;
      /**
       * Input
       * @description Text to classify.
       */
      input: string | string[];
    };
    /** DocumentURLChunk */
    DocumentURLChunk: {
      /**
       * @description discriminator enum property added by openapi-typescript
       * @enum {string}
       */
      type: "document_url";
      /** Document Url */
      document_url: string;
      /**
       * Document Name
       * @description The filename of the document
       */
      document_name?: string | null;
    };
    /** EmbeddingRequest */
    EmbeddingRequest: {
      /**
       * Model
       * @description ID of the model to use.
       * @default mistral-embed
       */
      model: string;
      /**
       * Input
       * @description Text to embed.
       * @example [
       *       "Embed this sentence.",
       *       "As well as this one."
       *     ]
       */
      input: string | string[];
    };
    /** FIMCompletionRequest */
    FIMCompletionRequest: {
      /**
       * Model
       * @description ID of the model to use. Only compatible for now with:
       *       - `codestral-2405`
       *       - `codestral-latest`
       * @default codestral-2405
       */
      model: string;
      /**
       * Temperature
       * @description What sampling temperature to use, we recommend between 0.0 and 0.7. Higher values like 0.7 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. We generally recommend altering this or `top_p` but not both. The default value varies depending on the model you are targeting. Call the `/models` endpoint to retrieve the appropriate value.
       */
      temperature?: number | null;
      /**
       * Top P
       * @description Nucleus sampling, where the model considers the results of the tokens with `top_p` probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered. We generally recommend altering this or `temperature` but not both.
       * @default 1
       */
      top_p: number;
      /**
       * Max Tokens
       * @description The maximum number of tokens to generate in the completion. The token count of your prompt plus `max_tokens` cannot exceed the model's context length.
       */
      max_tokens?: number | null;
      /**
       * Stream
       * @description Whether to stream back partial progress. If set, tokens will be sent as data-only server-side events as they become available, with the stream terminated by a data: [DONE] message. Otherwise, the server will hold the request open until the timeout or until completion, with the response containing the full result as JSON.
       * @default false
       */
      stream: boolean;
      /**
       * Stop
       * @description Stop generation if this token is detected. Or if one of these tokens is detected when providing an array
       */
      stop?: string | string[];
      /**
       * Random Seed
       * @description The seed to use for random sampling. If set, different calls will generate deterministic results.
       */
      random_seed?: number | null;
      /**
       * Prompt
       * @description The text/code to complete.
       */
      prompt: string;
      /**
       * Suffix
       * @description Optional text/code that adds more context for the model. When given a `prompt` and a `suffix` the model will fill what is between them. When `suffix` is not provided, the model will simply execute completion starting with `prompt`.
       * @default
       */
      suffix: string | null;
      /**
       * Min Tokens
       * @description The minimum number of tokens to generate in the completion.
       */
      min_tokens?: number | null;
    };
    /** Function */
    Function: {
      /** Name */
      name: string;
      /**
       * Description
       * @default
       */
      description: string;
      /**
       * Strict
       * @default false
       */
      strict: boolean;
      /** Parameters */
      parameters: {
        [key: string]: unknown;
      };
    };
    /** FunctionCall */
    FunctionCall: {
      /** Name */
      name: string;
      /** Arguments */
      arguments:
        | {
            [key: string]: unknown;
          }
        | string;
    };
    /**
     * FunctionName
     * @description this restriction of `Function` is used to select a specific function to call
     */
    FunctionName: {
      /** Name */
      name: string;
    };
    /** ImageURL */
    ImageURL: {
      /** Url */
      url: string;
      /** Detail */
      detail?: string | null;
    };
    /**
     * ImageURLChunk
     * @description {"type":"image_url","image_url":{"url":"data:image/png;base64,iVBORw0
     */
    ImageURLChunk: {
      /** Image Url */
      image_url: components["schemas"]["ImageURL"] | string;
      /**
       * @description discriminator enum property added by openapi-typescript
       * @enum {string}
       */
      type: "image_url";
    };
    /** JsonSchema */
    JsonSchema: {
      /** Name */
      name: string;
      /** Description */
      description?: string | null;
      /** Schema */
      schema: {
        [key: string]: unknown;
      };
      /**
       * Strict
       * @default false
       */
      strict: boolean;
    };
    /** OCRImageObject */
    OCRImageObject: {
      /**
       * Id
       * @description Image ID for extracted image in a page
       */
      id: string;
      /**
       * Top Left X
       * @description X coordinate of top-left corner of the extracted image
       */
      top_left_x: number | null;
      /**
       * Top Left Y
       * @description Y coordinate of top-left corner of the extracted image
       */
      top_left_y: number | null;
      /**
       * Bottom Right X
       * @description X coordinate of bottom-right corner of the extracted image
       */
      bottom_right_x: number | null;
      /**
       * Bottom Right Y
       * @description Y coordinate of bottom-right corner of the extracted image
       */
      bottom_right_y: number | null;
      /**
       * Image Base64
       * @description Base64 string of the extracted image
       */
      image_base64?: string | null;
    };
    /** OCRPageDimensions */
    OCRPageDimensions: {
      /**
       * Dpi
       * @description Dots per inch of the page-image
       */
      dpi: number;
      /**
       * Height
       * @description Height of the image in pixels
       */
      height: number;
      /**
       * Width
       * @description Width of the image in pixels
       */
      width: number;
    };
    /** OCRPageObject */
    OCRPageObject: {
      /**
       * Index
       * @description The page index in a pdf document starting from 0
       */
      index: number;
      /**
       * Markdown
       * @description The markdown string response of the page
       */
      markdown: string;
      /**
       * Images
       * @description List of all extracted images in the page
       */
      images: components["schemas"]["OCRImageObject"][];
      /** @description The dimensions of the PDF Page's screenshot image */
      dimensions: components["schemas"]["OCRPageDimensions"] | null;
    };
    /** OCRRequest */
    OCRRequest: {
      /** Model */
      model: string | null;
      /** Id */
      id?: string;
      /**
       * Document
       * @description Document to run OCR on
       */
      document:
        | components["schemas"]["DocumentURLChunk"]
        | components["schemas"]["ImageURLChunk"];
      /**
       * Pages
       * @description Specific pages user wants to process in various formats: single number, range, or list of both. Starts from 0
       */
      pages?: number[] | null;
      /**
       * Include Image Base64
       * @description Include image URLs in response
       */
      include_image_base64?: boolean | null;
      /**
       * Image Limit
       * @description Max images to extract
       */
      image_limit?: number | null;
      /**
       * Image Min Size
       * @description Minimum height and width of image to extract
       */
      image_min_size?: number | null;
    };
    /** OCRResponse */
    OCRResponse: {
      /**
       * Pages
       * @description List of OCR info for pages.
       */
      pages: components["schemas"]["OCRPageObject"][];
      /**
       * Model
       * @description The model used to generate the OCR.
       */
      model: string;
      /** @description Usage info for the OCR request. */
      usage_info: components["schemas"]["OCRUsageInfo"];
    };
    /** OCRUsageInfo */
    OCRUsageInfo: {
      /**
       * Pages Processed
       * @description Number of pages processed
       */
      pages_processed: number;
      /**
       * Doc Size Bytes
       * @description Document size in bytes
       */
      doc_size_bytes?: number | null;
    };
    /** Prediction */
    Prediction: {
      /**
       * Type
       * @default content
       * @constant
       */
      type: "content";
      /**
       * Content
       * @default
       */
      content: string;
    };
    /** ReferenceChunk */
    ReferenceChunk: {
      /** Reference Ids */
      reference_ids: number[];
      /**
       * @description discriminator enum property added by openapi-typescript
       * @enum {string}
       */
      type: "reference";
    };
    /** ResponseFormat */
    ResponseFormat: {
      /** @default text */
      type: components["schemas"]["ResponseFormats"];
      json_schema?: components["schemas"]["JsonSchema"] | null;
    };
    /**
     * ResponseFormats
     * @description An object specifying the format that the model must output. Setting to `{ "type": "json_object" }` enables JSON mode, which guarantees the message the model generates is in JSON. When using JSON mode you MUST also instruct the model to produce JSON yourself with a system or a user message.
     * @enum {string}
     */
    ResponseFormats: "text" | "json_object" | "json_schema";
    /** SystemMessage */
    SystemMessage: {
      /** Content */
      content: string | components["schemas"]["TextChunk"][];
      /**
       * @description discriminator enum property added by openapi-typescript
       * @enum {string}
       */
      role: "system";
    };
    /** TextChunk */
    TextChunk: {
      /** Text */
      text: string;
      /**
       * @description discriminator enum property added by openapi-typescript
       * @enum {string}
       */
      type: "text";
    };
    /** Tool */
    Tool: {
      /** @default function */
      type: components["schemas"]["ToolTypes"];
      function: components["schemas"]["Function"];
    };
    /** ToolCall */
    ToolCall: {
      /**
       * Id
       * @default null
       */
      id: string;
      /** @default function */
      type: components["schemas"]["ToolTypes"];
      function: components["schemas"]["FunctionCall"];
      /**
       * Index
       * @default 0
       */
      index: number;
    };
    /**
     * ToolChoice
     * @description ToolChoice is either a ToolChoiceEnum or a ToolChoice
     */
    ToolChoice: {
      /** @default function */
      type: components["schemas"]["ToolTypes"];
      function: components["schemas"]["FunctionName"];
    };
    /**
     * ToolChoiceEnum
     * @enum {string}
     */
    ToolChoiceEnum: "auto" | "none" | "any" | "required";
    /** ToolMessage */
    ToolMessage: {
      /** Content */
      content: string | null | components["schemas"]["ContentChunk"][];
      /** Tool Call Id */
      tool_call_id?: string | null;
      /** Name */
      name?: string | null;
      /**
       * @description discriminator enum property added by openapi-typescript
       * @enum {string}
       */
      role: "tool";
    };
    /**
     * ToolTypes
     * @enum {string}
     */
    ToolTypes: "function";
    /** UserMessage */
    UserMessage: {
      /** Content */
      content: string | null | components["schemas"]["ContentChunk"][];
      /**
       * @description discriminator enum property added by openapi-typescript
       * @enum {string}
       */
      role: "user";
    };
    /** AgentsCompletionRequest */
    AgentsCompletionRequest: {
      /**
       * Max Tokens
       * @description The maximum number of tokens to generate in the completion. The token count of your prompt plus `max_tokens` cannot exceed the model's context length.
       */
      max_tokens?: number | null;
      /**
       * Stream
       * @description Whether to stream back partial progress. If set, tokens will be sent as data-only server-side events as they become available, with the stream terminated by a data: [DONE] message. Otherwise, the server will hold the request open until the timeout or until completion, with the response containing the full result as JSON.
       * @default false
       */
      stream: boolean;
      /**
       * Stop
       * @description Stop generation if this token is detected. Or if one of these tokens is detected when providing an array
       */
      stop?: string | string[];
      /**
       * Random Seed
       * @description The seed to use for random sampling. If set, different calls will generate deterministic results.
       */
      random_seed?: number | null;
      /**
       * Messages
       * @description The prompt(s) to generate completions for, encoded as a list of dict with role and content.
       */
      messages: (
        | components["schemas"]["SystemMessage"]
        | components["schemas"]["UserMessage"]
        | components["schemas"]["AssistantMessage"]
        | components["schemas"]["ToolMessage"]
      )[];
      response_format?: components["schemas"]["ResponseFormat"];
      /** Tools */
      tools?: components["schemas"]["Tool"][] | null;
      /**
       * Tool Choice
       * @default auto
       */
      tool_choice:
        | components["schemas"]["ToolChoice"]
        | components["schemas"]["ToolChoiceEnum"];
      /**
       * Presence Penalty
       * @description presence_penalty determines how much the model penalizes the repetition of words or phrases. A higher presence penalty encourages the model to use a wider variety of words and phrases, making the output more diverse and creative.
       * @default 0
       */
      presence_penalty: number;
      /**
       * Frequency Penalty
       * @description frequency_penalty penalizes the repetition of words based on their frequency in the generated text. A higher frequency penalty discourages the model from repeating words that have already appeared frequently in the output, promoting diversity and reducing repetition.
       * @default 0
       */
      frequency_penalty: number;
      /**
       * N
       * @description Number of completions to return for each request, input tokens are only billed once.
       */
      n?: number | null;
      /**
       * @description Enable users to specify expected results, optimizing response times by leveraging known or predictable content. This approach is especially effective for updating text documents or code files with minimal changes, reducing latency while maintaining high-quality results.
       * @default {
       *       "type": "content",
       *       "content": ""
       *     }
       */
      prediction: components["schemas"]["Prediction"];
      /** @description The ID of the agent to use for this completion. */
      agent_id: string;
    };
    /** ContentChunk */
    ContentChunk:
      | components["schemas"]["TextChunk"]
      | components["schemas"]["ImageURLChunk"]
      | components["schemas"]["DocumentURLChunk"]
      | components["schemas"]["ReferenceChunk"];
    /** UsageInfo */
    UsageInfo: {
      /** @example 16 */
      prompt_tokens: number;
      /** @example 34 */
      completion_tokens: number;
      /** @example 50 */
      total_tokens: number;
    };
    /** ResponseBase */
    ResponseBase: {
      /** @example cmpl-e5cc70bb28c444948073e77776eb30ef */
      id?: string;
      /** @example chat.completion */
      object?: string;
      /** @example mistral-small-latest */
      model?: string;
      usage?: components["schemas"]["UsageInfo"];
    };
    /** ChatCompletionChoice */
    ChatCompletionChoice: {
      /** @example 0 */
      index: number;
      message: components["schemas"]["AssistantMessage"];
      /**
       * @example stop
       * @enum {string}
       */
      finish_reason:
        | "stop"
        | "length"
        | "model_length"
        | "error"
        | "tool_calls";
    };
    /** DeltaMessage */
    DeltaMessage: {
      role?: string | null;
      content?: string | null | components["schemas"]["ContentChunk"][];
      tool_calls?: null | components["schemas"]["ToolCall"][];
    };
    ChatCompletionResponseBase: components["schemas"]["ResponseBase"] & {
      /** @example 1702256327 */
      created?: number;
    };
    ChatCompletionResponse: components["schemas"]["ChatCompletionResponseBase"] & {
      choices?: components["schemas"]["ChatCompletionChoice"][];
    };
    FIMCompletionResponse: components["schemas"]["ChatCompletionResponse"] & {
      /** @example codestral-latest */
      model?: string;
    };
    /** EmbeddingResponseData */
    EmbeddingResponseData: {
      /** @example embedding */
      object?: string;
      /** @example [
       *       0.1,
       *       0.2,
       *       0.3
       *     ] */
      embedding?: number[];
      /** @example 0 */
      index?: number;
    };
    EmbeddingResponse: components["schemas"]["ResponseBase"] & {
      data: [components["schemas"]["EmbeddingResponseData"]];
    };
    /** ClassificationResponse */
    ClassificationResponse: {
      /** @example mod-e5cc70bb28c444948073e77776eb30ef */
      id?: string;
      model?: string;
      results?: [components["schemas"]["ClassificationObject"]];
    };
    /** ClassificationObject */
    ClassificationObject: {
      /** @description Classifier result thresholded */
      categories?: {
        [key: string]: boolean;
      };
      /** @description Classifier result */
      category_scores?: {
        [key: string]: number;
      };
    };
    /** CompletionEvent */
    CompletionEvent: {
      data: components["schemas"]["CompletionChunk"];
    };
    /** CompletionChunk */
    CompletionChunk: {
      id: string;
      object?: string;
      created?: number;
      model: string;
      usage?: components["schemas"]["UsageInfo"];
      choices: components["schemas"]["CompletionResponseStreamChoice"][];
    };
    /** CompletionResponseStreamChoice */
    CompletionResponseStreamChoice: {
      index: number;
      delta: components["schemas"]["DeltaMessage"];
      /** @enum {string|null} */
      finish_reason: "stop" | "length" | "error" | "tool_calls" | null;
    };
  };
  responses: never;
  parameters: never;
  requestBodies: never;
  headers: never;
  pathItems: never;
}
export type $defs = Record<string, never>;
export interface operations {
  list_models_v1_models_get: {
    parameters: {
      query?: never;
      header?: never;
      path?: never;
      cookie?: never;
    };
    requestBody?: never;
    responses: {
      /** @description Successful Response */
      200: {
        headers: {
          [name: string]: unknown;
        };
        content: {
          "application/json": components["schemas"]["ModelList"];
        };
      };
      /** @description Validation Error */
      422: {
        headers: {
          [name: string]: unknown;
        };
        content: {
          "application/json": components["schemas"]["HTTPValidationError"];
        };
      };
    };
  };
  retrieve_model_v1_models__model_id__get: {
    parameters: {
      query?: never;
      header?: never;
      path: {
        /**
         * @description The ID of the model to retrieve.
         * @example ft:open-mistral-7b:587a6b29:20240514:7e773925
         */
        model_id: string;
      };
      cookie?: never;
    };
    requestBody?: never;
    responses: {
      /** @description Successful Response */
      200: {
        headers: {
          [name: string]: unknown;
        };
        content: {
          "application/json":
            | components["schemas"]["BaseModelCard"]
            | components["schemas"]["FTModelCard"];
        };
      };
      /** @description Validation Error */
      422: {
        headers: {
          [name: string]: unknown;
        };
        content: {
          "application/json": components["schemas"]["HTTPValidationError"];
        };
      };
    };
  };
  delete_model_v1_models__model_id__delete: {
    parameters: {
      query?: never;
      header?: never;
      path: {
        /**
         * @description The ID of the model to delete.
         * @example ft:open-mistral-7b:587a6b29:20240514:7e773925
         */
        model_id: string;
      };
      cookie?: never;
    };
    requestBody?: never;
    responses: {
      /** @description Successful Response */
      200: {
        headers: {
          [name: string]: unknown;
        };
        content: {
          "application/json": components["schemas"]["DeleteModelOut"];
        };
      };
      /** @description Validation Error */
      422: {
        headers: {
          [name: string]: unknown;
        };
        content: {
          "application/json": components["schemas"]["HTTPValidationError"];
        };
      };
    };
  };
  files_api_routes_list_files: {
    parameters: {
      query?: {
        page?: number;
        page_size?: number;
        sample_type?: components["schemas"]["SampleType"][] | null;
        source?: components["schemas"]["Source"][] | null;
        search?: string | null;
        purpose?: components["schemas"]["FilePurpose"] | null;
      };
      header?: never;
      path?: never;
      cookie?: never;
    };
    requestBody?: never;
    responses: {
      /** @description OK */
      200: {
        headers: {
          [name: string]: unknown;
        };
        content: {
          "application/json": components["schemas"]["ListFilesOut"];
        };
      };
    };
  };
  files_api_routes_upload_file: {
    parameters: {
      query?: never;
      header?: never;
      path?: never;
      cookie?: never;
    };
    requestBody: {
      content: {
        "multipart/form-data": {
          /**
           * File
           * Format: binary
           * @description The File object (not file name) to be uploaded.
           *      To upload a file and specify a custom file name you should format your request as such:
           *      ```bash
           *      file=@path/to/your/file.jsonl;filename=custom_name.jsonl
           *      ```
           *      Otherwise, you can just keep the original file name:
           *      ```bash
           *      file=@path/to/your/file.jsonl
           *      ```
           */
          file: string;
          purpose?: components["schemas"]["FilePurpose"];
        };
      };
    };
    responses: {
      /** @description OK */
      200: {
        headers: {
          [name: string]: unknown;
        };
        content: {
          "application/json": components["schemas"]["UploadFileOut"];
        };
      };
    };
  };
  files_api_routes_retrieve_file: {
    parameters: {
      query?: never;
      header?: never;
      path: {
        file_id: string;
      };
      cookie?: never;
    };
    requestBody?: never;
    responses: {
      /** @description OK */
      200: {
        headers: {
          [name: string]: unknown;
        };
        content: {
          "application/json": components["schemas"]["RetrieveFileOut"];
        };
      };
    };
  };
  files_api_routes_delete_file: {
    parameters: {
      query?: never;
      header?: never;
      path: {
        file_id: string;
      };
      cookie?: never;
    };
    requestBody?: never;
    responses: {
      /** @description OK */
      200: {
        headers: {
          [name: string]: unknown;
        };
        content: {
          "application/json": components["schemas"]["DeleteFileOut"];
        };
      };
    };
  };
  files_api_routes_download_file: {
    parameters: {
      query?: never;
      header?: never;
      path: {
        file_id: string;
      };
      cookie?: never;
    };
    requestBody?: never;
    responses: {
      /** @description OK */
      200: {
        headers: {
          [name: string]: unknown;
        };
        content: {
          "application/octet-stream": string;
        };
      };
    };
  };
  files_api_routes_get_signed_url: {
    parameters: {
      query?: {
        /** @description Number of hours before the url becomes invalid. Defaults to 24h */
        expiry?: number;
      };
      header?: never;
      path: {
        file_id: string;
      };
      cookie?: never;
    };
    requestBody?: never;
    responses: {
      /** @description OK */
      200: {
        headers: {
          [name: string]: unknown;
        };
        content: {
          "application/json": components["schemas"]["FileSignedURL"];
        };
      };
    };
  };
  jobs_api_routes_fine_tuning_get_fine_tuning_jobs: {
    parameters: {
      query?: {
        /** @description The page number of the results to be returned. */
        page?: number;
        /** @description The number of items to return per page. */
        page_size?: number;
        /** @description The model name used for fine-tuning to filter on. When set, the other results are not displayed. */
        model?: string | null;
        /** @description The date/time to filter on. When set, the results for previous creation times are not displayed. */
        created_after?: string | null;
        /** @description When set, only return results for jobs created by the API caller. Other results are not displayed. */
        created_by_me?: boolean;
        /** @description The current job state to filter on. When set, the other results are not displayed. */
        status?:
          | (
              | "QUEUED"
              | "STARTED"
              | "VALIDATING"
              | "VALIDATED"
              | "RUNNING"
              | "FAILED_VALIDATION"
              | "FAILED"
              | "SUCCESS"
              | "CANCELLED"
              | "CANCELLATION_REQUESTED"
            )
          | null;
        /** @description The Weights and Biases project to filter on. When set, the other results are not displayed. */
        wandb_project?: string | null;
        /** @description The Weight and Biases run name to filter on. When set, the other results are not displayed. */
        wandb_name?: string | null;
        /** @description The model suffix to filter on. When set, the other results are not displayed. */
        suffix?: string | null;
      };
      header?: never;
      path?: never;
      cookie?: never;
    };
    requestBody?: never;
    responses: {
      /** @description OK */
      200: {
        headers: {
          [name: string]: unknown;
        };
        content: {
          "application/json": components["schemas"]["JobsOut"];
        };
      };
    };
  };
  jobs_api_routes_fine_tuning_create_fine_tuning_job: {
    parameters: {
      query?: {
        /** @description * If `true` the job is not spawned, instead the query returns a handful of useful metadata
         *       for the user to perform sanity checks (see `LegacyJobMetadataOut` response).
         *     * Otherwise, the job is started and the query returns the job ID along with some of the
         *       input parameters (see `JobOut` response).
         *      */
        dry_run?: boolean | null;
      };
      header?: never;
      path?: never;
      cookie?: never;
    };
    requestBody: {
      content: {
        "application/json": components["schemas"]["JobIn"];
      };
    };
    responses: {
      /** @description OK */
      200: {
        headers: {
          [name: string]: unknown;
        };
        content: {
          "application/json":
            | components["schemas"]["JobOut"]
            | components["schemas"]["LegacyJobMetadataOut"];
        };
      };
    };
  };
  jobs_api_routes_fine_tuning_get_fine_tuning_job: {
    parameters: {
      query?: never;
      header?: never;
      path: {
        /** @description The ID of the job to analyse. */
        job_id: string;
      };
      cookie?: never;
    };
    requestBody?: never;
    responses: {
      /** @description OK */
      200: {
        headers: {
          [name: string]: unknown;
        };
        content: {
          "application/json": components["schemas"]["DetailedJobOut"];
        };
      };
    };
  };
  jobs_api_routes_fine_tuning_cancel_fine_tuning_job: {
    parameters: {
      query?: never;
      header?: never;
      path: {
        /** @description The ID of the job to cancel. */
        job_id: string;
      };
      cookie?: never;
    };
    requestBody?: never;
    responses: {
      /** @description OK */
      200: {
        headers: {
          [name: string]: unknown;
        };
        content: {
          "application/json": components["schemas"]["DetailedJobOut"];
        };
      };
    };
  };
  jobs_api_routes_fine_tuning_start_fine_tuning_job: {
    parameters: {
      query?: never;
      header?: never;
      path: {
        job_id: string;
      };
      cookie?: never;
    };
    requestBody?: never;
    responses: {
      /** @description OK */
      200: {
        headers: {
          [name: string]: unknown;
        };
        content: {
          "application/json": components["schemas"]["DetailedJobOut"];
        };
      };
    };
  };
  jobs_api_routes_fine_tuning_update_fine_tuned_model: {
    parameters: {
      query?: never;
      header?: never;
      path: {
        /**
         * @description The ID of the model to update.
         * @example ft:open-mistral-7b:587a6b29:20240514:7e773925
         */
        model_id: string;
      };
      cookie?: never;
    };
    requestBody: {
      content: {
        "application/json": components["schemas"]["UpdateFTModelIn"];
      };
    };
    responses: {
      /** @description OK */
      200: {
        headers: {
          [name: string]: unknown;
        };
        content: {
          "application/json": components["schemas"]["FTModelOut"];
        };
      };
    };
  };
  jobs_api_routes_fine_tuning_archive_fine_tuned_model: {
    parameters: {
      query?: never;
      header?: never;
      path: {
        /**
         * @description The ID of the model to archive.
         * @example ft:open-mistral-7b:587a6b29:20240514:7e773925
         */
        model_id: string;
      };
      cookie?: never;
    };
    requestBody?: never;
    responses: {
      /** @description OK */
      200: {
        headers: {
          [name: string]: unknown;
        };
        content: {
          "application/json": components["schemas"]["ArchiveFTModelOut"];
        };
      };
    };
  };
  jobs_api_routes_fine_tuning_unarchive_fine_tuned_model: {
    parameters: {
      query?: never;
      header?: never;
      path: {
        /**
         * @description The ID of the model to unarchive.
         * @example ft:open-mistral-7b:587a6b29:20240514:7e773925
         */
        model_id: string;
      };
      cookie?: never;
    };
    requestBody?: never;
    responses: {
      /** @description OK */
      200: {
        headers: {
          [name: string]: unknown;
        };
        content: {
          "application/json": components["schemas"]["UnarchiveFTModelOut"];
        };
      };
    };
  };
  jobs_api_routes_batch_get_batch_jobs: {
    parameters: {
      query?: {
        page?: number;
        page_size?: number;
        model?: string | null;
        metadata?: {
          [key: string]: unknown;
        } | null;
        created_after?: string | null;
        created_by_me?: boolean;
        status?: components["schemas"]["BatchJobStatus"] | null;
      };
      header?: never;
      path?: never;
      cookie?: never;
    };
    requestBody?: never;
    responses: {
      /** @description OK */
      200: {
        headers: {
          [name: string]: unknown;
        };
        content: {
          "application/json": components["schemas"]["BatchJobsOut"];
        };
      };
    };
  };
  jobs_api_routes_batch_create_batch_job: {
    parameters: {
      query?: never;
      header?: never;
      path?: never;
      cookie?: never;
    };
    requestBody: {
      content: {
        "application/json": components["schemas"]["BatchJobIn"];
      };
    };
    responses: {
      /** @description OK */
      200: {
        headers: {
          [name: string]: unknown;
        };
        content: {
          "application/json": components["schemas"]["BatchJobOut"];
        };
      };
    };
  };
  jobs_api_routes_batch_get_batch_job: {
    parameters: {
      query?: never;
      header?: never;
      path: {
        job_id: string;
      };
      cookie?: never;
    };
    requestBody?: never;
    responses: {
      /** @description OK */
      200: {
        headers: {
          [name: string]: unknown;
        };
        content: {
          "application/json": components["schemas"]["BatchJobOut"];
        };
      };
    };
  };
  jobs_api_routes_batch_cancel_batch_job: {
    parameters: {
      query?: never;
      header?: never;
      path: {
        job_id: string;
      };
      cookie?: never;
    };
    requestBody?: never;
    responses: {
      /** @description OK */
      200: {
        headers: {
          [name: string]: unknown;
        };
        content: {
          "application/json": components["schemas"]["BatchJobOut"];
        };
      };
    };
  };
  chat_completion_v1_chat_completions_post: {
    parameters: {
      query?: never;
      header?: never;
      path?: never;
      cookie?: never;
    };
    requestBody: {
      content: {
        "application/json": components["schemas"]["ChatCompletionRequest"];
      };
    };
    responses: {
      /** @description Successful Response */
      200: {
        headers: {
          [name: string]: unknown;
        };
        content: {
          "application/json": components["schemas"]["ChatCompletionResponse"];
          "text/event-stream": components["schemas"]["CompletionEvent"];
        };
      };
      /** @description Validation Error */
      422: {
        headers: {
          [name: string]: unknown;
        };
        content: {
          "application/json": components["schemas"]["HTTPValidationError"];
        };
      };
    };
  };
  fim_completion_v1_fim_completions_post: {
    parameters: {
      query?: never;
      header?: never;
      path?: never;
      cookie?: never;
    };
    requestBody: {
      content: {
        "application/json": components["schemas"]["FIMCompletionRequest"];
      };
    };
    responses: {
      /** @description Successful Response */
      200: {
        headers: {
          [name: string]: unknown;
        };
        content: {
          "application/json": components["schemas"]["FIMCompletionResponse"];
          "text/event-stream": components["schemas"]["CompletionEvent"];
        };
      };
      /** @description Validation Error */
      422: {
        headers: {
          [name: string]: unknown;
        };
        content: {
          "application/json": components["schemas"]["HTTPValidationError"];
        };
      };
    };
  };
  ocr_v1_ocr_post: {
    parameters: {
      query?: never;
      header?: never;
      path?: never;
      cookie?: never;
    };
    requestBody: {
      content: {
        "application/json": components["schemas"]["OCRRequest"];
      };
    };
    responses: {
      /** @description Successful Response */
      200: {
        headers: {
          [name: string]: unknown;
        };
        content: {
          "application/json": components["schemas"]["OCRResponse"];
        };
      };
      /** @description Validation Error */
      422: {
        headers: {
          [name: string]: unknown;
        };
        content: {
          "application/json": components["schemas"]["HTTPValidationError"];
        };
      };
    };
  };
  moderations_v1_moderations_post: {
    parameters: {
      query?: never;
      header?: never;
      path?: never;
      cookie?: never;
    };
    requestBody: {
      content: {
        "application/json": components["schemas"]["ClassificationRequest"];
      };
    };
    responses: {
      /** @description Successful Response */
      200: {
        headers: {
          [name: string]: unknown;
        };
        content: {
          "application/json": components["schemas"]["ClassificationResponse"];
        };
      };
      /** @description Validation Error */
      422: {
        headers: {
          [name: string]: unknown;
        };
        content: {
          "application/json": components["schemas"]["HTTPValidationError"];
        };
      };
    };
  };
  moderations_chat_v1_chat_moderations_post: {
    parameters: {
      query?: never;
      header?: never;
      path?: never;
      cookie?: never;
    };
    requestBody: {
      content: {
        "application/json": components["schemas"]["ChatModerationRequest"];
      };
    };
    responses: {
      /** @description Successful Response */
      200: {
        headers: {
          [name: string]: unknown;
        };
        content: {
          "application/json": components["schemas"]["ClassificationResponse"];
        };
      };
      /** @description Validation Error */
      422: {
        headers: {
          [name: string]: unknown;
        };
        content: {
          "application/json": components["schemas"]["HTTPValidationError"];
        };
      };
    };
  };
  embeddings_v1_embeddings_post: {
    parameters: {
      query?: never;
      header?: never;
      path?: never;
      cookie?: never;
    };
    requestBody: {
      content: {
        "application/json": components["schemas"]["EmbeddingRequest"];
      };
    };
    responses: {
      /** @description Successful Response */
      200: {
        headers: {
          [name: string]: unknown;
        };
        content: {
          "application/json": components["schemas"]["EmbeddingResponse"];
        };
      };
      /** @description Validation Error */
      422: {
        headers: {
          [name: string]: unknown;
        };
        content: {
          "application/json": components["schemas"]["HTTPValidationError"];
        };
      };
    };
  };
  agents_completion_v1_agents_completions_post: {
    parameters: {
      query?: never;
      header?: never;
      path?: never;
      cookie?: never;
    };
    requestBody: {
      content: {
        "application/json": components["schemas"]["AgentsCompletionRequest"];
      };
    };
    responses: {
      /** @description Successful Response */
      200: {
        headers: {
          [name: string]: unknown;
        };
        content: {
          "application/json": components["schemas"]["ChatCompletionResponse"];
        };
      };
      /** @description Validation Error */
      422: {
        headers: {
          [name: string]: unknown;
        };
        content: {
          "application/json": components["schemas"]["HTTPValidationError"];
        };
      };
    };
  };
}
